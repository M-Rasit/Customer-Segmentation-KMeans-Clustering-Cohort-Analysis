{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Customer_Segmentation_Colab.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNe1dg1AVPmM"
      },
      "source": [
        "# ** RFM Customer Segmentation & Cohort Analysis Project **  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SCOFEfqiqa1"
      },
      "source": [
        "## Determines\n",
        "\n",
        "Using the [Online Retail dataset](https://archive.ics.uci.edu/ml/datasets/Online+Retail) from the UCI Machine Learning Repository for exploratory data analysis, ***Customer Segmentation***, ***RFM Analysis***, ***K-Means Clustering*** and ***Cohort Analysis***.\n",
        "\n",
        "This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n",
        "\n",
        "Feature Information:\n",
        "\n",
        "**InvoiceNo**: Invoice number. *Nominal*, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation. \n",
        "<br>\n",
        "**StockCode**: Product (item) code. *Nominal*, a 5-digit integral number uniquely assigned to each distinct product.\n",
        "<br>\n",
        "**Description**: Product (item) name. *Nominal*. \n",
        "<br>\n",
        "**Quantity**: The quantities of each product (item) per transaction. *Numeric*.\n",
        "<br>\n",
        "**InvoiceDate**: Invoice Date and time. *Numeric*, the day and time when each transaction was generated.\n",
        "<br>\n",
        "**UnitPrice**: Unit price. *Numeric*, Product price per unit in sterling.\n",
        "<br>\n",
        "**CustomerID**: Customer number. *Nominal*, a 5-digit integral number uniquely assigned to each customer.\n",
        "<br>\n",
        "**Country**: Country name. *Nominal*, the name of the country where each customer resides.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-NlVU1UQGVA"
      },
      "source": [
        "# 1. Data Cleaning & Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L63G_-Dqiqa3"
      },
      "source": [
        "## Import Modules, Load Data & Data Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Zb5JfOiqa3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibaMgBR-sT4Y"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KcNIxn4rABW"
      },
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/Customer Segmentation/Online Retail.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM89jzdzrABY"
      },
      "source": [
        "df.shape # Shape of data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cno2-lxprABf"
      },
      "source": [
        "df.head(5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeoI4SPYrABi"
      },
      "source": [
        "df.info() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFQkg_ZtrABk"
      },
      "source": [
        "df.isnull().sum()/ len(df) * 100 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8grmjVUlbFD-"
      },
      "source": [
        "Description and CustomerID columns have missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RryOsmE4rAB0"
      },
      "source": [
        "df.describe() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNIRUgBwbZzB"
      },
      "source": [
        "Quantity and UnitPrice columns have negative values. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YECMxCzUQGV7"
      },
      "source": [
        "### i. Take a look at relationships between InvoiceNo, Quantity and UnitPrice columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hd8Psh_rACF"
      },
      "source": [
        "df[\"InvoiceNo\"].value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "badajT_8uEjA"
      },
      "source": [
        "df[\"Quantity\"].value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl7E_SgquEod"
      },
      "source": [
        "df[\"UnitPrice\"].value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUCimWWygwSy"
      },
      "source": [
        "We see that there are negative values in the Quantity and UnitPrice columns. These are possibly canceled and returned orders. Let's check it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYpUTTg6uEqx"
      },
      "source": [
        "df_three = df[[\"InvoiceNo\", \"Quantity\", \"UnitPrice\"]] # Created a new dataframe for InvoiceNo, Quantity, UnitPrice columns\r\n",
        "df_three[df_three[\"Quantity\"] < 0] # Quantity lower than 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkvdwOvD_OOe"
      },
      "source": [
        "df_three[(df_three[\"Quantity\"] < 0) & (df_three[\"InvoiceNo\"].str.contains(\"C\"))] # InvoiceNo startswith C and Quantity lower than 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj9DtopEAWR7"
      },
      "source": [
        "df_three[(df_three[\"Quantity\"] < 0) & (df_three[\"InvoiceNo\"].str.contains(\"C\") == False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odJlGaAHef72"
      },
      "source": [
        "There are 9192 rows that Quantity is lower than 0 and 7856 rows's InvoiceNo starts with \"C\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7he27Yp8y_P"
      },
      "source": [
        "df_three[df_three[\"UnitPrice\"] < 0] # UnitPrice lower than 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39lRow4TgIvK"
      },
      "source": [
        "df_three[df_three[\"InvoiceNo\"].str.contains(\"A\") == True] # InvoiceNo contains A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA-cJgOQ88qD"
      },
      "source": [
        "df_three[(df_three[\"UnitPrice\"] < 0) & (df_three[\"InvoiceNo\"].str.contains(\"A\"))] # UnitPrice is lower than 0 and InvoiceNo starts with A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDuRPKL5AfxF"
      },
      "source": [
        "df_three[(df_three[\"UnitPrice\"] > 0) & (df_three[\"InvoiceNo\"].str.contains(\"A\") == True)] # UnitPrice is greater than 0 and InvoiceNo starts with A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ-VE4f4frSN"
      },
      "source": [
        "There are 2 rows that UnitPrice column is lower than 0  and  3 columns start with A."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsy9r73Z9Gfx"
      },
      "source": [
        "print(\"The number of rows that InvoiceNo starts with C:\", df[\"InvoiceNo\"].str.contains(\"C\").sum())\r\n",
        "print(\"The number of rows that InvoiceNo starts with A:\", df[\"InvoiceNo\"].str.contains(\"A\").sum())\r\n",
        "print(\"The number of rows that Quantity lower than 0:\", sum(df[\"Quantity\"] < 0))\r\n",
        "print(\"The number of rows that UnitPrice lower than 0:\", sum(df[\"UnitPrice\"] < 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OoPE-QLiqa4"
      },
      "source": [
        "### ii. What does the letter \"C\" in the InvoiceNo column mean?\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgN0C80Giqa5"
      },
      "source": [
        "df[df[\"InvoiceNo\"].str.contains(\"C\") == True]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VerE5-8_hE_9"
      },
      "source": [
        "df[(df[\"Quantity\"] < 0) & (df[\"InvoiceNo\"].str.contains(\"C\"))].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6uOx_JKBfRW"
      },
      "source": [
        "df[(df[\"InvoiceNo\"].str.contains(\"C\")) & (df[\"Quantity\"] > 0)].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l8WXSx6iYkG"
      },
      "source": [
        "If the invoice number starts with the letter \"C\", it means the order was cancelled. Or those who abandon their order. When we filter canceled orders by Quantity > 0 or filter non-canceled orders by Quantity < 0 nothing returns, this confirms that negative values mean the order was canceled. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHS2Wy8jjO9w"
      },
      "source": [
        "df[df[\"UnitPrice\"] < 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU85zHMqWHSx"
      },
      "source": [
        "df[df[\"InvoiceNo\"].str.contains(\"A\") == True]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEmH1wj3VvAn"
      },
      "source": [
        "df[(df[\"UnitPrice\"] < 0) & (df[\"InvoiceNo\"].str.contains(\"A\"))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3qanBGdkDPV"
      },
      "source": [
        "df[df[\"StockCode\"] == \"B\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrp8logRQGWA"
      },
      "source": [
        "Negative UnitPrice refers to doubtful process and their CustomerID's are missing values. Also StockCode's are B and InvoiceNo starts with A. This refers to doubtful process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXVVls6sQGVQ"
      },
      "source": [
        "### iii. Handling Missing Values and Clean the Data from the Noise and Missing Values\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yExVxnQsiqa6"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQtZK5paQGVf"
      },
      "source": [
        "Since the customer ID's are missing, lets assume these orders were not made by the customers already in the data set because those customers already have ID's. \n",
        "\n",
        "We also don't want to assign these orders to those customers because this would alter the insights we draw from the data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkbAUgf6Xiy-"
      },
      "source": [
        "df2 = df # In the further researches, this can be helpful."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIcp2muIYp1F"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuLMOgLAXt6Q"
      },
      "source": [
        "df[\"Description\"].fillna(\"\", inplace=True) # Fill Description column with \"\" \r\n",
        "df.dropna(inplace=True) # Drop missing values from Dataset. This will drop rows which CustomerID is null."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1D8HkJcXuAE"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwsnQSr4YNfx"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25MkNjZqQGWC"
      },
      "source": [
        "### Exploring the Orders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OAkPoUjiqa7"
      },
      "source": [
        "1. The unique number of InvoiceNo  per customer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1A76M7Jiqa7"
      },
      "source": [
        "print(\"The number of unique InvoiceNo per each customer:\", df[\"InvoiceNo\"].nunique() / df[\"CustomerID\"].nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di03OKjzQGWE"
      },
      "source": [
        "2. What's the average number of unique items per order or per customer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16JPO8yreKpv"
      },
      "source": [
        "print(\"Per order, average number of unique items:\" ,df.groupby(\"InvoiceNo\")[\"StockCode\"].nunique().mean()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUKzA73dQGWH"
      },
      "source": [
        "3. Let's see how this compares to the number of unique products per customer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8uzjYyKiqa7"
      },
      "source": [
        "print(\"Per customer, average number of unique items:\" ,df.groupby(\"CustomerID\")[\"StockCode\"].nunique().mean()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_Ozp-U5QGWK"
      },
      "source": [
        "### vi. Explore Customers by Country"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP6M3isLiqa8"
      },
      "source": [
        "1. What's the total revenue per country?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDM2MPIlfriq"
      },
      "source": [
        "plt.figure(figsize=(24,12))\r\n",
        "plt.title(\"Total Revenue per Country\", c=\"blue\", size=14)\r\n",
        "plt.xticks(rotation=45)\r\n",
        "total_revenue_per_country = df.groupby(\"Country\")[\"UnitPrice\"].sum().sort_values(ascending=False)\r\n",
        "sns.barplot(x=total_revenue_per_country.index, y=total_revenue_per_country.values) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk64qtEliqa8"
      },
      "source": [
        "2. Visualize number of customer per country"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atuYU8W2iqa8"
      },
      "source": [
        "plt.figure(figsize=(24,12))\r\n",
        "plt.title(\"Total Customer per Country\", c=\"blue\", size=14)\r\n",
        "plt.xticks(rotation=45)\r\n",
        "total_customer_per_country = df.groupby(\"Country\")[\"CustomerID\"].nunique().sort_values(ascending=False)\r\n",
        "sns.barplot(x=total_customer_per_country.index, y=total_customer_per_country.values) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TD66fT3iqa8"
      },
      "source": [
        "3. Visualize total cost per country"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMwKZi9hs7C4"
      },
      "source": [
        "df[\"Cost\"] = df[\"Quantity\"] * df[\"UnitPrice\"] # Created Cost column with multiplying Quantity and UnitPrice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i0nVOggiqa8"
      },
      "source": [
        "plt.figure(figsize=(24,12))\r\n",
        "plt.title(\"Total Cost per Country\", c=\"blue\", size=14)\r\n",
        "plt.xticks(rotation=45)\r\n",
        "total_cost_per_country = df.groupby(\"Country\")[\"Cost\"].sum().sort_values(ascending=False)\r\n",
        "sns.barplot(x=total_cost_per_country.index, y=total_cost_per_country.values) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwfJuBVCQGWR"
      },
      "source": [
        "#### The UK not only has the most sales revenue, but also the most customers. Since the majority of this data set contains orders from the UK, we can explore the UK market further by finding out what products the customers buy together and any other buying behaviors to improve our sales and targeting strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A25nnqIQGWR"
      },
      "source": [
        "### vii. Explore the UK Market\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtWchB1Ziqa9"
      },
      "source": [
        "1. Creating df_uk DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsdH3cuZiqa9"
      },
      "source": [
        "df_uk = df[df[\"Country\"] == \"United Kingdom\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is5kus2bQGWT"
      },
      "source": [
        "2. What are the most popular products that are bought in the UK?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCN56amLiqa9"
      },
      "source": [
        "df_uk[df_uk[\"StockCode\"] == df_uk[\"StockCode\"].value_counts().index[0]][\"Description\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHbqJD7bQGWU"
      },
      "source": [
        "### We will continue analyzing the UK transactions with customer segmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAtzWvugQGWV"
      },
      "source": [
        "# 2. RFM Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5uUAUQpQGWV"
      },
      "source": [
        "**[RFM](https://www.putler.com/rfm-analysis/) (Recency, Frequency, Monetary) Analysis** is a customer segmentation technique for analyzing customer value based on past buying behavior. RFM analysis was first used by the direct mail industry more than four decades ago, yet it is still an effective way to optimize your marketing.\n",
        "\n",
        "\n",
        "- RECENCY (R): Time since last purchase\n",
        "- FREQUENCY (F): Total number of purchases\n",
        "- MONETARY VALUE (M): Total monetary value\n",
        "\n",
        "Benefits of RFM Analysis\n",
        "\n",
        "- Increased customer retention\n",
        "- Increased response rate\n",
        "- Increased conversion rate\n",
        "- Increased revenue\n",
        "\n",
        "RFM Analysis answers the following questions:\n",
        " - Who are our best customers?\n",
        " - Who has the potential to be converted into more profitable customers?\n",
        " - Which customers do we need to retain?\n",
        " - Which group of customers is most likely to respond to our marketing campaign?\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryjdgFdm0CpZ"
      },
      "source": [
        "import datetime as dt\r\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rYM4MJsQGWW"
      },
      "source": [
        "### ii. Review df_uk DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQHyAJNeiqa-"
      },
      "source": [
        "df_uk.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvfCcPLgQGWa"
      },
      "source": [
        "### iii. Recency: Days since last purchase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Gzn6r6QGWb"
      },
      "source": [
        "1. Choosing a date as a point of reference to evaluate how many days ago was the customer's last purchase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2kMMn8G48Fm"
      },
      "source": [
        "new_date = dt.datetime.strptime(\"2011-12-10\", \"%Y-%m-%d\") # Choosing a date, I chose the 1 day later of last date in dataset.\r\n",
        "new_date = new_date.date()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge34PCT0iqa-"
      },
      "source": [
        "2. Creating a new column called Date which contains the invoice date without the timestamp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsaFUydXiqa_"
      },
      "source": [
        "df_uk[\"Date\"] = df_uk[\"InvoiceDate\"].dt.date "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KJzP5Ldiqa_"
      },
      "source": [
        "3. Group by CustomerID and check the last date of purchase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8kMt-Uyiqa_"
      },
      "source": [
        "last_date_of_purchase = df_uk.groupby(\"CustomerID\")[\"Date\"].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68PPHBw_BTQt"
      },
      "source": [
        "last_date_of_purchase.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zxs1mzPiqa_"
      },
      "source": [
        "4. Calculate the days since last purchase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTeKws6giqa_"
      },
      "source": [
        "recency = new_date - last_date_of_purchase\r\n",
        "recency = recency.astype(\"str\")\r\n",
        "\r\n",
        "def get_number(x):\r\n",
        "  return re.findall(\"\\d+\", x)[0]\r\n",
        "\r\n",
        "recency = recency.apply(get_number)\r\n",
        "recency.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB9a0AL9iqa_"
      },
      "source": [
        "6. Plot RFM distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8e-QiwRiqa_"
      },
      "source": [
        "plt.figure(figsize=(24,12))\r\n",
        "plt.title(\"RFM Distributions for Recency\", c=\"blue\", size=14)\r\n",
        "sns.histplot(recency.sort_values().values, color=\"Red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAjKZD0KQGWg"
      },
      "source": [
        "### iv. Frequency: Number of purchases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDoNslseiqbA"
      },
      "source": [
        "1. Copy of df_uk and drop duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gk2gokFiqbA"
      },
      "source": [
        "df_uk_copy = df_uk.drop_duplicates()\r\n",
        "print(\"df_uk shape:\",df_uk.shape)\r\n",
        "print(\"df_uk_copy shape:\", df_uk_copy.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KrnuXrLiqbA"
      },
      "source": [
        "2. The frequency of purchases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LTM_cxpiqbA"
      },
      "source": [
        "frequency = df_uk_copy.groupby(\"CustomerID\")[\"InvoiceNo\"].count()\r\n",
        "frequency.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9NNBCNgiqbA"
      },
      "source": [
        "3. Plot RFM distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUtZAHu1iqbA"
      },
      "source": [
        "plt.figure(figsize=(24,12))\r\n",
        "plt.title(\"RFM Distributions for Frequency\", c=\"blue\", size=14)\r\n",
        "sns.histplot(frequency.sort_values(ascending=False).values, color=\"Red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUY3gKjQQGWh"
      },
      "source": [
        "### v. Monetary: Total amount of money spent\n",
        "\n",
        "The monetary value is calculated by adding together the cost of the customers' purchases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_4_QLWtiqbA"
      },
      "source": [
        "1. Calculate sum total cost by customers and named \"Monetary\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bilKBqvIiqbB"
      },
      "source": [
        "monetary = df_uk.groupby(\"CustomerID\")[\"Cost\"].sum()\r\n",
        "monetary.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHR_oE0FNzsi"
      },
      "source": [
        "df[df[\"CustomerID\"] == 12346]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYsaCPRDiqbB"
      },
      "source": [
        "2. Plot RFM distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd41fD67iqbB"
      },
      "source": [
        "plt.figure(figsize=(24,12))\r\n",
        "plt.title(\"RFM Distributions for Monetary\", c=\"blue\", size=14)\r\n",
        "sns.histplot(monetary.sort_values(ascending=False).values, color=\"Red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeaecPkSQGWj"
      },
      "source": [
        "### vi. Creating RFM Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M88KNSbyiqbB"
      },
      "source": [
        "df_rfm = pd.concat([recency, frequency, monetary], axis=1)\r\n",
        "df_rfm = df_rfm.rename(columns={\"Date\":\"Recency\", \"InvoiceNo\":\"Frequency\", \"Cost\":\"Monetary\"})\r\n",
        "df_rfm[\"Recency\"] = df_rfm[\"Recency\"].astype(\"int\")\r\n",
        "df_rfm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULWwsxCkQGWl"
      },
      "source": [
        "# 3. Customer Segmentation with RFM Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anOsOGpfQGWl"
      },
      "source": [
        "##  RFM Score\n",
        "\n",
        "The simplest way to create customer segments from an RFM model is by using **Quartiles**. We will assign a score from 1 to 4 to each category (Recency, Frequency, and Monetary) with 4 being the highest/best value. The final RFM score is calculated by combining all RFM values. For Customer Segmentation, you will use the df_rfm data set resulting from the RFM analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiwXSsP7iqbB"
      },
      "source": [
        "1. Dividing the df_rfm into quarters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFQJGPYHiqbC"
      },
      "source": [
        "df_rfm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnkzCAf9QGWo"
      },
      "source": [
        "### i. Creating the RFM Segmentation Table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLIB-z-_iqbC"
      },
      "source": [
        "1. Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXnW03R8iqbC"
      },
      "source": [
        "def recency_quarter(x):\r\n",
        "  recency_quantile = df_rfm[\"Recency\"].quantile([0.25, 0.50, 0.75]).values \r\n",
        "  if x <= recency_quantile[0]:\r\n",
        "    return 4\r\n",
        "  elif x <= recency_quantile[1]:\r\n",
        "    return 3\r\n",
        "  elif x <= recency_quantile[2]:\r\n",
        "    return 2\r\n",
        "  else:\r\n",
        "    return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG3SdLzcbbye"
      },
      "source": [
        "def frequency_quarter(x):\r\n",
        "  frequency_quantile = df_rfm[\"Frequency\"].quantile([0.25, 0.50, 0.75]).values \r\n",
        "  if x <= frequency_quantile[0]:\r\n",
        "    return 1\r\n",
        "  elif x <= frequency_quantile[1]:\r\n",
        "    return 2\r\n",
        "  elif x <= frequency_quantile[2]:\r\n",
        "    return 3\r\n",
        "  else:\r\n",
        "    return 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtrSui5Rbb06"
      },
      "source": [
        "def monetary_quarter(x):\r\n",
        "  monetary_quantile = df_rfm[\"Monetary\"].quantile([0.25, 0.50, 0.75]).values \r\n",
        "  if x <= monetary_quantile[0]:\r\n",
        "    return 1\r\n",
        "  elif x <= monetary_quantile[1]:\r\n",
        "    return 2\r\n",
        "  elif x <= monetary_quantile[2]:\r\n",
        "    return 3\r\n",
        "  else:\r\n",
        "    return 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLDK_XeLiqbC"
      },
      "source": [
        "2. Scoring customers from 1 - 4 with functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYs5mE2ScPw4"
      },
      "source": [
        "df_rfm[\"RecencyScore\"] = df_rfm[\"Recency\"].apply(recency_quarter)\r\n",
        "df_rfm[\"FrequencyScore\"] = df_rfm[\"Frequency\"].apply(frequency_quarter)\r\n",
        "df_rfm[\"MonetaryScore\"] = df_rfm[\"Monetary\"].apply(monetary_quarter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c36zAUjCc8HT"
      },
      "source": [
        "df_rfm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JskteCFdQGWq"
      },
      "source": [
        "3. Combining scores for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLRO76Ojdo3s"
      },
      "source": [
        "df_rfm[\"CombinedScore\"] = df_rfm[\"RecencyScore\"].astype(\"str\") + df_rfm[\"FrequencyScore\"].astype(\"str\") + df_rfm[\"MonetaryScore\"].astype(\"str\")\r\n",
        "df_rfm[\"CombinedScore\"] = df_rfm[\"CombinedScore\"].astype(\"int\")\r\n",
        "print(\"Combined Score unique values:\", df_rfm[\"CombinedScore\"].nunique())\r\n",
        "df_rfm[\"CombinedScore\"].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twEI_k_Zg03S"
      },
      "source": [
        "df_rfm[\"CombinedScoreTotal\"] = df_rfm[\"RecencyScore\"] + df_rfm[\"FrequencyScore\"] + df_rfm[\"MonetaryScore\"]\r\n",
        "df_rfm[\"CombinedScoreTotal\"] = df_rfm[\"CombinedScoreTotal\"].astype(\"int\")\r\n",
        "print(\"Combined Score Total unique values:\", df_rfm[\"CombinedScoreTotal\"].nunique())\r\n",
        "df_rfm[\"CombinedScoreTotal\"].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZf4N-23hc5A"
      },
      "source": [
        "CombinedScore has 61 unique values. On the other hand, CombinedScoreTotal has 10 unique values. Labelling CombinedScoreTotal is more accountable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUUdk5P-h3HM"
      },
      "source": [
        "df_rfm.drop(\"CombinedScore\", axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWwWeyjPiqbC"
      },
      "source": [
        "4. Defining rfm_level function that tags customers by using RFM_Scrores and Creating RFM Level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37Y4QC7KtcK-"
      },
      "source": [
        "df_rfm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ctEHZWwiDCK"
      },
      "source": [
        "def rfm_tags(x):\r\n",
        "  if x <= 4:\r\n",
        "    return \"Requires Action\"\r\n",
        "  elif x <= 6:\r\n",
        "    return \"Needs Attention\"\r\n",
        "  elif x <= 8:\r\n",
        "    return \"Promising\"\r\n",
        "  elif x <= 10:\r\n",
        "    return \"Loyal\"\r\n",
        "  else:\r\n",
        "    return \"Best\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5IEzSGEtApk"
      },
      "source": [
        "df_rfm[\"rfm_level\"] = df_rfm[\"CombinedScoreTotal\"].apply(rfm_tags)\r\n",
        "df_rfm[\"rfm_level\"].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq36PiX3iqbD"
      },
      "source": [
        "5. Value counts for RFM level and average combined score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn5r5P2WiqbD"
      },
      "source": [
        "df_rfm.groupby(\"rfm_level\")[\"CombinedScoreTotal\"].count() # Size of each segment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKt-lgQKvTMj"
      },
      "source": [
        "df_rfm.groupby(\"rfm_level\")[\"CombinedScoreTotal\"].mean() # Average Combined Score of each segment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuZ5Olo4iqbD"
      },
      "source": [
        "## Plot RFM Segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STfELckwiqbD"
      },
      "source": [
        "1. Creating Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oef37q3diqbD"
      },
      "source": [
        "plt.figure(figsize=(12,8))\r\n",
        "plt.title(\"Countplot of RFM Segments\", c=\"blue\", size=14)\r\n",
        "sns.countplot(df_rfm[\"rfm_level\"], palette=\"magma\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te_6gUR5iqbD"
      },
      "source": [
        "2. How many customers do we have in each segment?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yfl71fdwikS"
      },
      "source": [
        "df_rfm.groupby(\"rfm_level\")[\"CombinedScoreTotal\"].count() # Size of each segment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RwemvLyQGWv"
      },
      "source": [
        "# 3. Applying K-Means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6WZ0PnZQGWv"
      },
      "source": [
        "Now that we have our customers segmented into 5 different categories, we can gain further insight into customer behavior by using predictive models in conjuction with out RFM model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrWIRLkMiqbE"
      },
      "source": [
        "## Data Pre-Processing and Exploring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLoRGR6NiqbE"
      },
      "source": [
        "df_rfm2 = df_rfm[[\"Recency\", \"Frequency\", \"Monetary\"]]\r\n",
        "df_rfm2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt50bw2OyZf7"
      },
      "source": [
        "df_rfm2.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6SGV0xoQGWw"
      },
      "source": [
        "### i. Feature Correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpMAiWNBiqbE"
      },
      "source": [
        "Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Cv8_EqiqbE"
      },
      "source": [
        "plt.figure(figsize=(8,6))\r\n",
        "sns.heatmap(df_rfm2.corr(), annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WhL5MBEQGWy"
      },
      "source": [
        "### ii. Visualize Feature Distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofAyjM65MVq"
      },
      "source": [
        "sns.pairplot(df_rfm2, aspect=2, height=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7JyGBug5tfU"
      },
      "source": [
        "### iii. Data Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wAL1bJHwkiv"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "scaler = StandardScaler()\r\n",
        "rfm_scaled = scaler.fit_transform(df_rfm2)\r\n",
        "rfm_scaled = pd.DataFrame(rfm_scaled, columns=[\"Recency\", \"Frequency\", \"Monetary\"])\r\n",
        "rfm_scaled.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC6dHnqKiqbF"
      },
      "source": [
        "2. Plot normalized data with scatter matrix or pairplot. Also evaluate results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB9jDUPriqbF"
      },
      "source": [
        "sns.pairplot(rfm_scaled, aspect=2, height=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35c0aDixQGW4"
      },
      "source": [
        "## K-Means Implementation\n",
        "\n",
        "We will try different cluster numbers and check their [silhouette coefficient](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html). The silhouette coefficient for a data point measures how similar it is to its assigned cluster from -1 (dissimilar) to 1 (similar). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JloMSEeriqbF"
      },
      "source": [
        "### i. Defining the Optimal Number of Clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McFq6IWZt5hg"
      },
      "source": [
        "[The Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2202eo2riqbF"
      },
      "source": [
        "from sklearn.cluster import KMeans\r\n",
        "from yellowbrick.cluster import KElbowVisualizer\r\n",
        "\r\n",
        "model = KMeans()\r\n",
        "visualizer = KElbowVisualizer(model, k=(2,10), timings=False)\r\n",
        "visualizer.fit(rfm_scaled)\r\n",
        "visualizer;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VByh70SSGAly"
      },
      "source": [
        "From the visualizer, optimal number of clusters is 5 and we can understand this from the various silhouette scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACT_d0UpwUSC"
      },
      "source": [
        "[Silhouette Coefficient](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS4TLbRniqbG"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\r\n",
        "\r\n",
        "for i in range(2,10):\r\n",
        "    kmeans = KMeans(n_clusters=i)\r\n",
        "    kmeans.fit(rfm_scaled)\r\n",
        "    print(f\"K Means Clustering --> n={i} and Silhouette Score =\",silhouette_score(rfm_scaled, kmeans.labels_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6dW2MWZiqbG"
      },
      "source": [
        "### ii. Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geMuViLniqbG"
      },
      "source": [
        "kmeans = KMeans(n_clusters=5)\r\n",
        "kmeans.fit(rfm_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqcSwNZTQGW7"
      },
      "source": [
        "### iii. Visualize the Clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfx5kzPriqbG"
      },
      "source": [
        "1. Creating a scatter plot and selecting cluster centers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyrovJB0iqbH"
      },
      "source": [
        "plt.figure(figsize=(15,8))\r\n",
        "rfm_scaled[\"cluster\"] = kmeans.labels_\r\n",
        "centroids = kmeans.cluster_centers_\r\n",
        "sns.scatterplot(rfm_scaled.iloc[:,0], rfm_scaled.iloc[:, 1], c=rfm_scaled[\"cluster\"], cmap=\"rainbow\")\r\n",
        "sns.scatterplot(list(centroids[:,0]), list(centroids[:,1]), s=500)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_M3sq-aqBCp"
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D # 3D Scatterplot\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "fig = plt.figure(figsize=(20,10))\r\n",
        "ax = plt.axes(projection='3d')\r\n",
        "ax.scatter3D(rfm_scaled.iloc[:,0], rfm_scaled.iloc[:, 2], c=rfm_scaled[\"cluster\"], cmap=\"rainbow\", s=50, alpha=0.5)\r\n",
        "ax.scatter3D(list(centroids[:,0]), list(centroids[:,1]), s=500, color=\"black\")\r\n",
        "ax.view_init(30, 35)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnFsEpRPB_Ni"
      },
      "source": [
        "### KMeans Clustering with Logaritm Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PWe7rHUB6BE"
      },
      "source": [
        "rfm_scaled = np.log1p(df_rfm2)\r\n",
        "rfm_scaled.fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8nc6N6iB6E5"
      },
      "source": [
        "sns.pairplot(rfm_scaled, aspect=2, height=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VxeC2hMB6I9"
      },
      "source": [
        "from sklearn.cluster import KMeans\r\n",
        "from yellowbrick.cluster import KElbowVisualizer\r\n",
        "\r\n",
        "model = KMeans()\r\n",
        "visualizer = KElbowVisualizer(model, k=(2,10), timings=False)\r\n",
        "visualizer.fit(rfm_scaled)\r\n",
        "visualizer;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeYwruuZB6Mg"
      },
      "source": [
        "for i in range(2,10):\r\n",
        "    kmeans = KMeans(n_clusters=i)\r\n",
        "    kmeans.fit(rfm_scaled)\r\n",
        "    print(f\"K Means Clustering --> n={i} and Silhouette Score =\",silhouette_score(rfm_scaled, kmeans.labels_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z68sE1a6B6P7"
      },
      "source": [
        "kmeans = KMeans(n_clusters=5)\r\n",
        "kmeans.fit(rfm_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6LbKC4QB6Sn"
      },
      "source": [
        "plt.figure(figsize=(15,8))\r\n",
        "rfm_scaled[\"cluster\"] = kmeans.labels_\r\n",
        "centroids = kmeans.cluster_centers_\r\n",
        "sns.scatterplot(rfm_scaled.iloc[:,0], rfm_scaled.iloc[:, 1], c=rfm_scaled[\"cluster\"], cmap=\"rainbow\")\r\n",
        "sns.scatterplot(list(centroids[:,0]), list(centroids[:,1]), s=500)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Faic2pRoB6Ys"
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\r\n",
        "%matplotlib inline\r\n",
        "fig = plt.figure(figsize=(20,10))\r\n",
        "ax = plt.axes(projection='3d')\r\n",
        "ax.scatter3D(rfm_scaled.iloc[:,0], rfm_scaled.iloc[:, 2], c=rfm_scaled[\"cluster\"], cmap=\"rainbow\", s=50, alpha=0.3)\r\n",
        "ax.scatter3D(list(centroids[:,0]), list(centroids[:,2]), s=750, color=\"black\", alpha=1)\r\n",
        "ax.view_init(50, 35)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4sHOvlniqbH"
      },
      "source": [
        " 2. Visualizing Cluster Id vs Recency, Cluster Id vs Frequency and Cluster Id vs Monetary using Box plot. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzPl-LXViqbH"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(25,8))\r\n",
        "\r\n",
        "sns.boxplot(x=\"cluster\", y=\"Recency\", data=rfm_scaled, ax=ax[0])\r\n",
        "sns.boxplot(x=\"cluster\", y=\"Frequency\", data=rfm_scaled, ax=ax[1])\r\n",
        "sns.boxplot(x=\"cluster\", y=\"Monetary\", data=rfm_scaled, ax=ax[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa78UhNKHelJ"
      },
      "source": [
        "We can determine clusters from the above plots. Lower Recency and higher Frequency and higher Monetary gives as perfect customer and the reverse tells us that we have to look that customers deeply."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRyku5qJiqbH"
      },
      "source": [
        "### iv. Assigning the Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7e3p8gkGfnI"
      },
      "source": [
        "def assign_label(x):\r\n",
        "  if x == 0:\r\n",
        "    return \"Best\"\r\n",
        "  elif x == 2:\r\n",
        "    return \"Loyal\"\r\n",
        "  elif x == 4:\r\n",
        "    return \"Promising\"\r\n",
        "  elif x == 1:\r\n",
        "    return \"Needs Attention\"\r\n",
        "  else:\r\n",
        "    return \"Requires Action\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDbw0xfOITPs"
      },
      "source": [
        "rfm_scaled[\"cluster_label\"] = rfm_scaled[\"cluster\"].apply(assign_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DiG6sxS4gWH"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "- Cluster 0 : The first cluster belongs to the \"Best Customers\" segment which we saw earlier as they purchase recently (R=4), frequent buyers (F=4), and spent the most (M=4)\n",
        "\n",
        "- Cluster 2 : These customers are also have low recency, high frequency and monetary purchase. They are not best customers but we can say that they are loyal. \n",
        "\n",
        "- Cluster 4 : These customers doesn'come recently but they were coming before and company can lose them. Company should pay more attention these customers and why they don't come recently. \n",
        "\n",
        "- Cluster 1 :  clusters can be interpreted as passer customers as their last purchase is long ago (R<=1),purchased very few (F>=2 & F < 4) and spent little (M>=4 & M < 4).Company has to come up with new strategies to make them permanent members. Low value customers\n",
        "\n",
        "- Cluster 0 : The last cluster is more related to the \"Almost Lost\" segment as they Haven’t purchased for some time(R=1), but used to purchase frequently and spent a lot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf4OsPmSQGXA"
      },
      "source": [
        "### v. Conclusion\n",
        "\n",
        "Discuss your final results. Compare your own labels from the Customer Segmentation with the labels found by K-Means."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiQ_bsaANu_C"
      },
      "source": [
        "print(\"Number of customers that rfm label and cluster label's equal:\", (df_rfm[\"rfm_level\"] == rfm_scaled[\"cluster_label\"]).sum())\r\n",
        "print(\"Number of customers that rfm label and cluster label's are not equal:\", (df_rfm[\"rfm_level\"] != rfm_scaled[\"cluster_label\"]).sum())\r\n",
        "\r\n",
        "plt.title(\"RFM Label & Cluster Label\", c=\"blue\", size=14)\r\n",
        "sns.countplot((df_rfm[\"rfm_level\"] == rfm_scaled[\"cluster_label\"]));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_y6AUiUPERy"
      },
      "source": [
        "df_compare = pd.concat([df_rfm[\"rfm_level\"], rfm_scaled[\"cluster_label\"]], axis=1)\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "plt.title(\"Countplot of Cluster Label by RMF Level\", c=\"blue\", size=14)\r\n",
        "sns.countplot(x=\"cluster_label\", hue=\"rfm_level\", data=df_compare)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac-hB82IRTeq"
      },
      "source": [
        "df_compare = pd.concat([df_rfm[\"rfm_level\"], rfm_scaled[\"cluster_label\"]], axis=1)\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "plt.title(\"Countplot of RMF Level by Cluster Label\", c=\"blue\", size=14)\r\n",
        "sns.countplot(x=\"rfm_level\", hue=\"cluster_label\", data=df_compare)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFaHgoLoQGXA"
      },
      "source": [
        "From the above plot we can conclude that both method determine \"Best\" customers. However Kmeans gives less value for \"Requires Action\" cluster and predict most of the rfm_level's loyal label as promising label. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiPd_IbnQGVn"
      },
      "source": [
        "# 5. Create Cohort & Conduct Cohort Analysis\n",
        "[Cohort Analysis](https://medium.com/swlh/cohort-analysis-using-python-and-pandas-d2a60f4d0a4d) is specifically useful in analyzing user growth patterns for products. In terms of a product, a cohort can be a group of people with the same sign-up date, the same usage starts month/date, or the same traffic source.\n",
        "Cohort analysis is an analytics method by which these groups can be tracked over time for finding key insights. This analysis can further be used to do customer segmentation and track metrics like retention, churn, and lifetime value.\n",
        "\n",
        "For e-commerce organizations, cohort analysis is a unique opportunity to find out which clients are the most valuable to their business. by performing Cohort analysis you can get the following answers to the following questions:\n",
        "\n",
        "- How much effective was a marketing campaign held in a particular time period?\n",
        "- Did the strategy employ to improve the conversion rates of Customers worked?\n",
        "- Should I focus more on retention rather than acquiring new customers?\n",
        "- Are my customer nurturing strategies effective?\n",
        "- Which marketing channels bring me the best results?\n",
        "- Is there a seasonality pattern in Customer behavior?\n",
        "- Along with various performance measures/metrics for your organization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo0GB_osiqbI"
      },
      "source": [
        "## Future Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVwPNjpyQGVo"
      },
      "source": [
        "### i. Extract the Month of the Purchase\n",
        "First we will create a function, which takes any date and returns the formatted date with day value as 1st of the same month and Year."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK1CqlNQiqbI"
      },
      "source": [
        "def day_first(x):\r\n",
        "\r\n",
        "  return dt.datetime(x.year, x.month, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQKsM_9IQGVq"
      },
      "source": [
        "Now we will use the function created above to convert all the invoice dates into respective month date format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL17u0dniqbJ"
      },
      "source": [
        "df[\"InvoiceMonth\"] = df[\"InvoiceDate\"].apply(day_first)\r\n",
        "df[\"InvoiceMonth\"].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmPVLTa4EMQR"
      },
      "source": [
        "df[\"CohortMonth\"] = df.groupby(\"CustomerID\")[\"InvoiceMonth\"].transform(min)\r\n",
        "df[\"CohortMonth\"].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPE7kTz2QGVs"
      },
      "source": [
        "### ii. Calculating time offset in Months i.e. Cohort Index:\n",
        "Calculating time offset for each transaction will allows us to report the metrics for each cohort in a comparable fashion.\n",
        "First, we will create 4 variables that capture the integer value of years, months for Invoice and Cohort Date using the get_date_int() function which we'll create it below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_3aYf4FiqbJ"
      },
      "source": [
        "def get_date_int(x):\r\n",
        "  \r\n",
        "  y = x.dt.year\r\n",
        "  m = x.dt.month\r\n",
        "  d = x.dt.day\r\n",
        "  return y, m, d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGm1eweDQGVu"
      },
      "source": [
        "We will use this function to extract the integer values for Invoice as well as Cohort Date in 3 seperate series for each of the two columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wF_ViD_iqbJ"
      },
      "source": [
        " inv_year, inv_month, inv_day = get_date_int(df[\"InvoiceMonth\"])\r\n",
        " coh_year, coh_month, coh_day = get_date_int(df[\"CohortMonth\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9jYVljviqbJ"
      },
      "source": [
        "Use the variables created above to calculate the difference in days and store them in cohort Index column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVlAYCbEiqbJ"
      },
      "source": [
        "years_diff = inv_year - coh_year\r\n",
        "months_diff = inv_month - coh_month\r\n",
        "\r\n",
        "df['CohortIndex'] = years_diff * 12 + months_diff + 1 # Find retention for monthly \r\n",
        "df[\"CohortIndex\"].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-t76CXSQGVw"
      },
      "source": [
        "## 1st Cohort: User number & Retention Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKvUWci9iqbJ"
      },
      "source": [
        "### i. Pivot Cohort and Cohort Retention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-8HzlZWiqbK"
      },
      "source": [
        "cohort_data = df.groupby([\"CohortMonth\", \"CohortIndex\"])[\"CustomerID\"].nunique().reset_index() # Unique number of customers in cohort month and cohort index.\r\n",
        "pivot_cohort = pd.pivot_table(data=cohort_data, index=\"CohortMonth\", columns=\"CohortIndex\", values=\"CustomerID\") # creating pivot table\r\n",
        "retention_rate = (pivot_cohort.divide(pivot_cohort.iloc[:,0], axis=0)).round(2) # retention rate\r\n",
        "retention_rate.index = retention_rate.index.strftime('%Y-%m')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63TIyBY6iqbK"
      },
      "source": [
        "### ii. Visualize analysis of cohort 1 using seaborn and matplotlib modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY7mPvCAiqbK"
      },
      "source": [
        "plt.figure(figsize=(18,10))\r\n",
        "sns.heatmap(data=retention_rate, cmap=\"Blues\", annot=True, fmt=\".0%\", vmax=0.8, vmin=0.0)\r\n",
        "plt.yticks(rotation=0);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yORYolvqQGV0"
      },
      "source": [
        "## 2nd Cohort: Average Quantity Sold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu1hM3CFiqbK"
      },
      "source": [
        "### i. Pivot Cohort and Cohort Retention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ8jlhPEiqbK"
      },
      "source": [
        "cohort_data = df.groupby([\"CohortMonth\", \"CohortIndex\"])[\"Quantity\"].mean().reset_index() # Quantity mean for cohort month and cohort index\r\n",
        "avg_quantity = pd.pivot_table(data=cohort_data, index=\"CohortMonth\", columns=\"CohortIndex\", values=\"Quantity\") \r\n",
        "avg_quantity.index = avg_quantity.index.strftime('%Y-%m')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3PJHMS6iqbK"
      },
      "source": [
        "### ii. Visualize analysis of cohort 2 using seaborn and matplotlib modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vuHi3wPiqbK"
      },
      "source": [
        "plt.figure(figsize=(18,10))\r\n",
        "sns.heatmap(data=avg_quantity, cmap=\"Reds\", annot=True)\r\n",
        "plt.yticks(rotation=0);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUoG5yUIQGV3"
      },
      "source": [
        "## 3rd Cohort: Average Sales\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKNS-mO5iqbL"
      },
      "source": [
        "### i. Pivot Cohort and Cohort Retention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2s-zyWeiqbL"
      },
      "source": [
        "cohort_data = df.groupby([\"CohortMonth\", \"CohortIndex\"])[\"Cost\"].mean().reset_index() # Cost mean for cohort month and cohort index\r\n",
        "avg_sales = pd.pivot_table(data=cohort_data, index=\"CohortMonth\", columns=\"CohortIndex\", values=\"Cost\")\r\n",
        "avg_sales.index = avg_sales.index.strftime('%m-%Y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRGOpeUPiqbL"
      },
      "source": [
        "### ii. Visualize analysis of cohort 3 using seaborn and matplotlib modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYkkDncXiqbL"
      },
      "source": [
        "plt.figure(figsize=(18,10))\r\n",
        "sns.heatmap(data=avg_sales, cmap=\"Greens\", annot=True)\r\n",
        "plt.yticks(rotation=0);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}